{"ast":null,"code":"// Process *this* and _that_\n//\n// Insert each marker as a separate text token, and add it to delimiter list\n//\nfunction emphasis_tokenize(state, silent) {\n  const start = state.pos;\n  const marker = state.src.charCodeAt(start);\n\n  if (silent) {\n    return false;\n  }\n\n  if (marker !== 0x5F\n  /* _ */\n  && marker !== 0x2A\n  /* * */\n  ) {\n      return false;\n    }\n\n  const scanned = state.scanDelims(state.pos, marker === 0x2A);\n\n  for (let i = 0; i < scanned.length; i++) {\n    const token = state.push('text', '', 0);\n    token.content = String.fromCharCode(marker);\n    state.delimiters.push({\n      // Char code of the starting marker (number).\n      //\n      marker,\n      // Total length of these series of delimiters.\n      //\n      length: scanned.length,\n      // A position of the token this delimiter corresponds to.\n      //\n      token: state.tokens.length - 1,\n      // If this delimiter is matched as a valid opener, `end` will be\n      // equal to its position, otherwise it's `-1`.\n      //\n      end: -1,\n      // Boolean flags that determine if this delimiter could open or close\n      // an emphasis.\n      //\n      open: scanned.can_open,\n      close: scanned.can_close\n    });\n  }\n\n  state.pos += scanned.length;\n  return true;\n}\n\nfunction postProcess(state, delimiters) {\n  const max = delimiters.length;\n\n  for (let i = max - 1; i >= 0; i--) {\n    const startDelim = delimiters[i];\n\n    if (startDelim.marker !== 0x5F\n    /* _ */\n    && startDelim.marker !== 0x2A\n    /* * */\n    ) {\n        continue;\n      } // Process only opening markers\n\n\n    if (startDelim.end === -1) {\n      continue;\n    }\n\n    const endDelim = delimiters[startDelim.end]; // If the previous delimiter has the same marker and is adjacent to this one,\n    // merge those into one strong delimiter.\n    //\n    // `<em><em>whatever</em></em>` -> `<strong>whatever</strong>`\n    //\n\n    const isStrong = i > 0 && delimiters[i - 1].end === startDelim.end + 1 && // check that first two markers match and adjacent\n    delimiters[i - 1].marker === startDelim.marker && delimiters[i - 1].token === startDelim.token - 1 && // check that last two markers are adjacent (we can safely assume they match)\n    delimiters[startDelim.end + 1].token === endDelim.token + 1;\n    const ch = String.fromCharCode(startDelim.marker);\n    const token_o = state.tokens[startDelim.token];\n    token_o.type = isStrong ? 'strong_open' : 'em_open';\n    token_o.tag = isStrong ? 'strong' : 'em';\n    token_o.nesting = 1;\n    token_o.markup = isStrong ? ch + ch : ch;\n    token_o.content = '';\n    const token_c = state.tokens[endDelim.token];\n    token_c.type = isStrong ? 'strong_close' : 'em_close';\n    token_c.tag = isStrong ? 'strong' : 'em';\n    token_c.nesting = -1;\n    token_c.markup = isStrong ? ch + ch : ch;\n    token_c.content = '';\n\n    if (isStrong) {\n      state.tokens[delimiters[i - 1].token].content = '';\n      state.tokens[delimiters[startDelim.end + 1].token].content = '';\n      i--;\n    }\n  }\n} // Walk through delimiter list and replace text tokens with tags\n//\n\n\nfunction emphasis_post_process(state) {\n  const tokens_meta = state.tokens_meta;\n  const max = state.tokens_meta.length;\n  postProcess(state, state.delimiters);\n\n  for (let curr = 0; curr < max; curr++) {\n    if (tokens_meta[curr] && tokens_meta[curr].delimiters) {\n      postProcess(state, tokens_meta[curr].delimiters);\n    }\n  }\n}\n\nexport default {\n  tokenize: emphasis_tokenize,\n  postProcess: emphasis_post_process\n};","map":{"version":3,"sources":["C:/Users/Trant/Documents/Lập Trình Web/5.font-end-react-fullstack/React - Copy/node_modules/markdown-it/lib/rules_inline/emphasis.mjs"],"names":["emphasis_tokenize","state","silent","start","pos","marker","src","charCodeAt","scanned","scanDelims","i","length","token","push","content","String","fromCharCode","delimiters","tokens","end","open","can_open","close","can_close","postProcess","max","startDelim","endDelim","isStrong","ch","token_o","type","tag","nesting","markup","token_c","emphasis_post_process","tokens_meta","curr","tokenize"],"mappings":"AAAA;AACA;AAEA;AACA;AACA,SAASA,iBAAT,CAA4BC,KAA5B,EAAmCC,MAAnC,EAA2C;AACzC,QAAMC,KAAK,GAAGF,KAAK,CAACG,GAApB;AACA,QAAMC,MAAM,GAAGJ,KAAK,CAACK,GAAN,CAAUC,UAAV,CAAqBJ,KAArB,CAAf;;AAEA,MAAID,MAAJ,EAAY;AAAE,WAAO,KAAP;AAAc;;AAE5B,MAAIG,MAAM,KAAK;AAAK;AAAhB,KAA2BA,MAAM,KAAK;AAAK;AAA/C,IAAwD;AAAE,aAAO,KAAP;AAAc;;AAExE,QAAMG,OAAO,GAAGP,KAAK,CAACQ,UAAN,CAAiBR,KAAK,CAACG,GAAvB,EAA4BC,MAAM,KAAK,IAAvC,CAAhB;;AAEA,OAAK,IAAIK,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGF,OAAO,CAACG,MAA5B,EAAoCD,CAAC,EAArC,EAAyC;AACvC,UAAME,KAAK,GAAGX,KAAK,CAACY,IAAN,CAAW,MAAX,EAAmB,EAAnB,EAAuB,CAAvB,CAAd;AACAD,IAAAA,KAAK,CAACE,OAAN,GAAgBC,MAAM,CAACC,YAAP,CAAoBX,MAApB,CAAhB;AAEAJ,IAAAA,KAAK,CAACgB,UAAN,CAAiBJ,IAAjB,CAAsB;AACpB;AACA;AACAR,MAAAA,MAHoB;AAKpB;AACA;AACAM,MAAAA,MAAM,EAAEH,OAAO,CAACG,MAPI;AASpB;AACA;AACAC,MAAAA,KAAK,EAAEX,KAAK,CAACiB,MAAN,CAAaP,MAAb,GAAsB,CAXT;AAapB;AACA;AACA;AACAQ,MAAAA,GAAG,EAAE,CAAC,CAhBc;AAkBpB;AACA;AACA;AACAC,MAAAA,IAAI,EAAEZ,OAAO,CAACa,QArBM;AAsBpBC,MAAAA,KAAK,EAAEd,OAAO,CAACe;AAtBK,KAAtB;AAwBD;;AAEDtB,EAAAA,KAAK,CAACG,GAAN,IAAaI,OAAO,CAACG,MAArB;AAEA,SAAO,IAAP;AACD;;AAED,SAASa,WAAT,CAAsBvB,KAAtB,EAA6BgB,UAA7B,EAAyC;AACvC,QAAMQ,GAAG,GAAGR,UAAU,CAACN,MAAvB;;AAEA,OAAK,IAAID,CAAC,GAAGe,GAAG,GAAG,CAAnB,EAAsBf,CAAC,IAAI,CAA3B,EAA8BA,CAAC,EAA/B,EAAmC;AACjC,UAAMgB,UAAU,GAAGT,UAAU,CAACP,CAAD,CAA7B;;AAEA,QAAIgB,UAAU,CAACrB,MAAX,KAAsB;AAAI;AAA1B,OAAqCqB,UAAU,CAACrB,MAAX,KAAsB;AAAI;AAAnE,MAA4E;AAC1E;AACD,OALgC,CAOjC;;;AACA,QAAIqB,UAAU,CAACP,GAAX,KAAmB,CAAC,CAAxB,EAA2B;AACzB;AACD;;AAED,UAAMQ,QAAQ,GAAGV,UAAU,CAACS,UAAU,CAACP,GAAZ,CAA3B,CAZiC,CAcjC;AACA;AACA;AACA;AACA;;AACA,UAAMS,QAAQ,GAAGlB,CAAC,GAAG,CAAJ,IACNO,UAAU,CAACP,CAAC,GAAG,CAAL,CAAV,CAAkBS,GAAlB,KAA0BO,UAAU,CAACP,GAAX,GAAiB,CADrC,IAEN;AACAF,IAAAA,UAAU,CAACP,CAAC,GAAG,CAAL,CAAV,CAAkBL,MAAlB,KAA6BqB,UAAU,CAACrB,MAHlC,IAINY,UAAU,CAACP,CAAC,GAAG,CAAL,CAAV,CAAkBE,KAAlB,KAA4Bc,UAAU,CAACd,KAAX,GAAmB,CAJzC,IAKN;AACAK,IAAAA,UAAU,CAACS,UAAU,CAACP,GAAX,GAAiB,CAAlB,CAAV,CAA+BP,KAA/B,KAAyCe,QAAQ,CAACf,KAAT,GAAiB,CANrE;AAQA,UAAMiB,EAAE,GAAGd,MAAM,CAACC,YAAP,CAAoBU,UAAU,CAACrB,MAA/B,CAAX;AAEA,UAAMyB,OAAO,GAAK7B,KAAK,CAACiB,MAAN,CAAaQ,UAAU,CAACd,KAAxB,CAAlB;AACAkB,IAAAA,OAAO,CAACC,IAAR,GAAkBH,QAAQ,GAAG,aAAH,GAAmB,SAA7C;AACAE,IAAAA,OAAO,CAACE,GAAR,GAAkBJ,QAAQ,GAAG,QAAH,GAAc,IAAxC;AACAE,IAAAA,OAAO,CAACG,OAAR,GAAkB,CAAlB;AACAH,IAAAA,OAAO,CAACI,MAAR,GAAkBN,QAAQ,GAAGC,EAAE,GAAGA,EAAR,GAAaA,EAAvC;AACAC,IAAAA,OAAO,CAAChB,OAAR,GAAkB,EAAlB;AAEA,UAAMqB,OAAO,GAAKlC,KAAK,CAACiB,MAAN,CAAaS,QAAQ,CAACf,KAAtB,CAAlB;AACAuB,IAAAA,OAAO,CAACJ,IAAR,GAAkBH,QAAQ,GAAG,cAAH,GAAoB,UAA9C;AACAO,IAAAA,OAAO,CAACH,GAAR,GAAkBJ,QAAQ,GAAG,QAAH,GAAc,IAAxC;AACAO,IAAAA,OAAO,CAACF,OAAR,GAAkB,CAAC,CAAnB;AACAE,IAAAA,OAAO,CAACD,MAAR,GAAkBN,QAAQ,GAAGC,EAAE,GAAGA,EAAR,GAAaA,EAAvC;AACAM,IAAAA,OAAO,CAACrB,OAAR,GAAkB,EAAlB;;AAEA,QAAIc,QAAJ,EAAc;AACZ3B,MAAAA,KAAK,CAACiB,MAAN,CAAaD,UAAU,CAACP,CAAC,GAAG,CAAL,CAAV,CAAkBE,KAA/B,EAAsCE,OAAtC,GAAgD,EAAhD;AACAb,MAAAA,KAAK,CAACiB,MAAN,CAAaD,UAAU,CAACS,UAAU,CAACP,GAAX,GAAiB,CAAlB,CAAV,CAA+BP,KAA5C,EAAmDE,OAAnD,GAA6D,EAA7D;AACAJ,MAAAA,CAAC;AACF;AACF;AACF,C,CAED;AACA;;;AACA,SAAS0B,qBAAT,CAAgCnC,KAAhC,EAAuC;AACrC,QAAMoC,WAAW,GAAGpC,KAAK,CAACoC,WAA1B;AACA,QAAMZ,GAAG,GAAGxB,KAAK,CAACoC,WAAN,CAAkB1B,MAA9B;AAEAa,EAAAA,WAAW,CAACvB,KAAD,EAAQA,KAAK,CAACgB,UAAd,CAAX;;AAEA,OAAK,IAAIqB,IAAI,GAAG,CAAhB,EAAmBA,IAAI,GAAGb,GAA1B,EAA+Ba,IAAI,EAAnC,EAAuC;AACrC,QAAID,WAAW,CAACC,IAAD,CAAX,IAAqBD,WAAW,CAACC,IAAD,CAAX,CAAkBrB,UAA3C,EAAuD;AACrDO,MAAAA,WAAW,CAACvB,KAAD,EAAQoC,WAAW,CAACC,IAAD,CAAX,CAAkBrB,UAA1B,CAAX;AACD;AACF;AACF;;AAED,eAAe;AACbsB,EAAAA,QAAQ,EAAEvC,iBADG;AAEbwB,EAAAA,WAAW,EAAEY;AAFA,CAAf","sourcesContent":["// Process *this* and _that_\n//\n\n// Insert each marker as a separate text token, and add it to delimiter list\n//\nfunction emphasis_tokenize (state, silent) {\n  const start = state.pos\n  const marker = state.src.charCodeAt(start)\n\n  if (silent) { return false }\n\n  if (marker !== 0x5F /* _ */ && marker !== 0x2A /* * */) { return false }\n\n  const scanned = state.scanDelims(state.pos, marker === 0x2A)\n\n  for (let i = 0; i < scanned.length; i++) {\n    const token = state.push('text', '', 0)\n    token.content = String.fromCharCode(marker)\n\n    state.delimiters.push({\n      // Char code of the starting marker (number).\n      //\n      marker,\n\n      // Total length of these series of delimiters.\n      //\n      length: scanned.length,\n\n      // A position of the token this delimiter corresponds to.\n      //\n      token: state.tokens.length - 1,\n\n      // If this delimiter is matched as a valid opener, `end` will be\n      // equal to its position, otherwise it's `-1`.\n      //\n      end: -1,\n\n      // Boolean flags that determine if this delimiter could open or close\n      // an emphasis.\n      //\n      open: scanned.can_open,\n      close: scanned.can_close\n    })\n  }\n\n  state.pos += scanned.length\n\n  return true\n}\n\nfunction postProcess (state, delimiters) {\n  const max = delimiters.length\n\n  for (let i = max - 1; i >= 0; i--) {\n    const startDelim = delimiters[i]\n\n    if (startDelim.marker !== 0x5F/* _ */ && startDelim.marker !== 0x2A/* * */) {\n      continue\n    }\n\n    // Process only opening markers\n    if (startDelim.end === -1) {\n      continue\n    }\n\n    const endDelim = delimiters[startDelim.end]\n\n    // If the previous delimiter has the same marker and is adjacent to this one,\n    // merge those into one strong delimiter.\n    //\n    // `<em><em>whatever</em></em>` -> `<strong>whatever</strong>`\n    //\n    const isStrong = i > 0 &&\n               delimiters[i - 1].end === startDelim.end + 1 &&\n               // check that first two markers match and adjacent\n               delimiters[i - 1].marker === startDelim.marker &&\n               delimiters[i - 1].token === startDelim.token - 1 &&\n               // check that last two markers are adjacent (we can safely assume they match)\n               delimiters[startDelim.end + 1].token === endDelim.token + 1\n\n    const ch = String.fromCharCode(startDelim.marker)\n\n    const token_o   = state.tokens[startDelim.token]\n    token_o.type    = isStrong ? 'strong_open' : 'em_open'\n    token_o.tag     = isStrong ? 'strong' : 'em'\n    token_o.nesting = 1\n    token_o.markup  = isStrong ? ch + ch : ch\n    token_o.content = ''\n\n    const token_c   = state.tokens[endDelim.token]\n    token_c.type    = isStrong ? 'strong_close' : 'em_close'\n    token_c.tag     = isStrong ? 'strong' : 'em'\n    token_c.nesting = -1\n    token_c.markup  = isStrong ? ch + ch : ch\n    token_c.content = ''\n\n    if (isStrong) {\n      state.tokens[delimiters[i - 1].token].content = ''\n      state.tokens[delimiters[startDelim.end + 1].token].content = ''\n      i--\n    }\n  }\n}\n\n// Walk through delimiter list and replace text tokens with tags\n//\nfunction emphasis_post_process (state) {\n  const tokens_meta = state.tokens_meta\n  const max = state.tokens_meta.length\n\n  postProcess(state, state.delimiters)\n\n  for (let curr = 0; curr < max; curr++) {\n    if (tokens_meta[curr] && tokens_meta[curr].delimiters) {\n      postProcess(state, tokens_meta[curr].delimiters)\n    }\n  }\n}\n\nexport default {\n  tokenize: emphasis_tokenize,\n  postProcess: emphasis_post_process\n}\n"]},"metadata":{},"sourceType":"module"}