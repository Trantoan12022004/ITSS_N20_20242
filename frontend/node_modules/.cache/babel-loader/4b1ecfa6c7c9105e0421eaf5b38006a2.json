{"ast":null,"code":"// ~~strike through~~\n//\n// Insert each marker as a separate text token, and add it to delimiter list\n//\nfunction strikethrough_tokenize(state, silent) {\n  const start = state.pos;\n  const marker = state.src.charCodeAt(start);\n\n  if (silent) {\n    return false;\n  }\n\n  if (marker !== 0x7E\n  /* ~ */\n  ) {\n      return false;\n    }\n\n  const scanned = state.scanDelims(state.pos, true);\n  let len = scanned.length;\n  const ch = String.fromCharCode(marker);\n\n  if (len < 2) {\n    return false;\n  }\n\n  let token;\n\n  if (len % 2) {\n    token = state.push('text', '', 0);\n    token.content = ch;\n    len--;\n  }\n\n  for (let i = 0; i < len; i += 2) {\n    token = state.push('text', '', 0);\n    token.content = ch + ch;\n    state.delimiters.push({\n      marker,\n      length: 0,\n      // disable \"rule of 3\" length checks meant for emphasis\n      token: state.tokens.length - 1,\n      end: -1,\n      open: scanned.can_open,\n      close: scanned.can_close\n    });\n  }\n\n  state.pos += scanned.length;\n  return true;\n}\n\nfunction postProcess(state, delimiters) {\n  let token;\n  const loneMarkers = [];\n  const max = delimiters.length;\n\n  for (let i = 0; i < max; i++) {\n    const startDelim = delimiters[i];\n\n    if (startDelim.marker !== 0x7E\n    /* ~ */\n    ) {\n        continue;\n      }\n\n    if (startDelim.end === -1) {\n      continue;\n    }\n\n    const endDelim = delimiters[startDelim.end];\n    token = state.tokens[startDelim.token];\n    token.type = 's_open';\n    token.tag = 's';\n    token.nesting = 1;\n    token.markup = '~~';\n    token.content = '';\n    token = state.tokens[endDelim.token];\n    token.type = 's_close';\n    token.tag = 's';\n    token.nesting = -1;\n    token.markup = '~~';\n    token.content = '';\n\n    if (state.tokens[endDelim.token - 1].type === 'text' && state.tokens[endDelim.token - 1].content === '~') {\n      loneMarkers.push(endDelim.token - 1);\n    }\n  } // If a marker sequence has an odd number of characters, it's splitted\n  // like this: `~~~~~` -> `~` + `~~` + `~~`, leaving one marker at the\n  // start of the sequence.\n  //\n  // So, we have to move all those markers after subsequent s_close tags.\n  //\n\n\n  while (loneMarkers.length) {\n    const i = loneMarkers.pop();\n    let j = i + 1;\n\n    while (j < state.tokens.length && state.tokens[j].type === 's_close') {\n      j++;\n    }\n\n    j--;\n\n    if (i !== j) {\n      token = state.tokens[j];\n      state.tokens[j] = state.tokens[i];\n      state.tokens[i] = token;\n    }\n  }\n} // Walk through delimiter list and replace text tokens with tags\n//\n\n\nfunction strikethrough_postProcess(state) {\n  const tokens_meta = state.tokens_meta;\n  const max = state.tokens_meta.length;\n  postProcess(state, state.delimiters);\n\n  for (let curr = 0; curr < max; curr++) {\n    if (tokens_meta[curr] && tokens_meta[curr].delimiters) {\n      postProcess(state, tokens_meta[curr].delimiters);\n    }\n  }\n}\n\nexport default {\n  tokenize: strikethrough_tokenize,\n  postProcess: strikethrough_postProcess\n};","map":{"version":3,"sources":["C:/Users/Trant/Documents/Lập Trình Web/5.font-end-react-fullstack/React - Copy/node_modules/markdown-it/lib/rules_inline/strikethrough.mjs"],"names":["strikethrough_tokenize","state","silent","start","pos","marker","src","charCodeAt","scanned","scanDelims","len","length","ch","String","fromCharCode","token","push","content","i","delimiters","tokens","end","open","can_open","close","can_close","postProcess","loneMarkers","max","startDelim","endDelim","type","tag","nesting","markup","pop","j","strikethrough_postProcess","tokens_meta","curr","tokenize"],"mappings":"AAAA;AACA;AAEA;AACA;AACA,SAASA,sBAAT,CAAiCC,KAAjC,EAAwCC,MAAxC,EAAgD;AAC9C,QAAMC,KAAK,GAAGF,KAAK,CAACG,GAApB;AACA,QAAMC,MAAM,GAAGJ,KAAK,CAACK,GAAN,CAAUC,UAAV,CAAqBJ,KAArB,CAAf;;AAEA,MAAID,MAAJ,EAAY;AAAE,WAAO,KAAP;AAAc;;AAE5B,MAAIG,MAAM,KAAK;AAAI;AAAnB,IAA4B;AAAE,aAAO,KAAP;AAAc;;AAE5C,QAAMG,OAAO,GAAGP,KAAK,CAACQ,UAAN,CAAiBR,KAAK,CAACG,GAAvB,EAA4B,IAA5B,CAAhB;AACA,MAAIM,GAAG,GAAGF,OAAO,CAACG,MAAlB;AACA,QAAMC,EAAE,GAAGC,MAAM,CAACC,YAAP,CAAoBT,MAApB,CAAX;;AAEA,MAAIK,GAAG,GAAG,CAAV,EAAa;AAAE,WAAO,KAAP;AAAc;;AAE7B,MAAIK,KAAJ;;AAEA,MAAIL,GAAG,GAAG,CAAV,EAAa;AACXK,IAAAA,KAAK,GAAWd,KAAK,CAACe,IAAN,CAAW,MAAX,EAAmB,EAAnB,EAAuB,CAAvB,CAAhB;AACAD,IAAAA,KAAK,CAACE,OAAN,GAAgBL,EAAhB;AACAF,IAAAA,GAAG;AACJ;;AAED,OAAK,IAAIQ,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGR,GAApB,EAAyBQ,CAAC,IAAI,CAA9B,EAAiC;AAC/BH,IAAAA,KAAK,GAAWd,KAAK,CAACe,IAAN,CAAW,MAAX,EAAmB,EAAnB,EAAuB,CAAvB,CAAhB;AACAD,IAAAA,KAAK,CAACE,OAAN,GAAgBL,EAAE,GAAGA,EAArB;AAEAX,IAAAA,KAAK,CAACkB,UAAN,CAAiBH,IAAjB,CAAsB;AACpBX,MAAAA,MADoB;AAEpBM,MAAAA,MAAM,EAAE,CAFY;AAEL;AACfI,MAAAA,KAAK,EAAEd,KAAK,CAACmB,MAAN,CAAaT,MAAb,GAAsB,CAHT;AAIpBU,MAAAA,GAAG,EAAE,CAAC,CAJc;AAKpBC,MAAAA,IAAI,EAAEd,OAAO,CAACe,QALM;AAMpBC,MAAAA,KAAK,EAAEhB,OAAO,CAACiB;AANK,KAAtB;AAQD;;AAEDxB,EAAAA,KAAK,CAACG,GAAN,IAAaI,OAAO,CAACG,MAArB;AAEA,SAAO,IAAP;AACD;;AAED,SAASe,WAAT,CAAsBzB,KAAtB,EAA6BkB,UAA7B,EAAyC;AACvC,MAAIJ,KAAJ;AACA,QAAMY,WAAW,GAAG,EAApB;AACA,QAAMC,GAAG,GAAGT,UAAU,CAACR,MAAvB;;AAEA,OAAK,IAAIO,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGU,GAApB,EAAyBV,CAAC,EAA1B,EAA8B;AAC5B,UAAMW,UAAU,GAAGV,UAAU,CAACD,CAAD,CAA7B;;AAEA,QAAIW,UAAU,CAACxB,MAAX,KAAsB;AAAI;AAA9B,MAAuC;AACrC;AACD;;AAED,QAAIwB,UAAU,CAACR,GAAX,KAAmB,CAAC,CAAxB,EAA2B;AACzB;AACD;;AAED,UAAMS,QAAQ,GAAGX,UAAU,CAACU,UAAU,CAACR,GAAZ,CAA3B;AAEAN,IAAAA,KAAK,GAAWd,KAAK,CAACmB,MAAN,CAAaS,UAAU,CAACd,KAAxB,CAAhB;AACAA,IAAAA,KAAK,CAACgB,IAAN,GAAgB,QAAhB;AACAhB,IAAAA,KAAK,CAACiB,GAAN,GAAgB,GAAhB;AACAjB,IAAAA,KAAK,CAACkB,OAAN,GAAgB,CAAhB;AACAlB,IAAAA,KAAK,CAACmB,MAAN,GAAgB,IAAhB;AACAnB,IAAAA,KAAK,CAACE,OAAN,GAAgB,EAAhB;AAEAF,IAAAA,KAAK,GAAWd,KAAK,CAACmB,MAAN,CAAaU,QAAQ,CAACf,KAAtB,CAAhB;AACAA,IAAAA,KAAK,CAACgB,IAAN,GAAgB,SAAhB;AACAhB,IAAAA,KAAK,CAACiB,GAAN,GAAgB,GAAhB;AACAjB,IAAAA,KAAK,CAACkB,OAAN,GAAgB,CAAC,CAAjB;AACAlB,IAAAA,KAAK,CAACmB,MAAN,GAAgB,IAAhB;AACAnB,IAAAA,KAAK,CAACE,OAAN,GAAgB,EAAhB;;AAEA,QAAIhB,KAAK,CAACmB,MAAN,CAAaU,QAAQ,CAACf,KAAT,GAAiB,CAA9B,EAAiCgB,IAAjC,KAA0C,MAA1C,IACA9B,KAAK,CAACmB,MAAN,CAAaU,QAAQ,CAACf,KAAT,GAAiB,CAA9B,EAAiCE,OAAjC,KAA6C,GADjD,EACsD;AACpDU,MAAAA,WAAW,CAACX,IAAZ,CAAiBc,QAAQ,CAACf,KAAT,GAAiB,CAAlC;AACD;AACF,GApCsC,CAsCvC;AACA;AACA;AACA;AACA;AACA;;;AACA,SAAOY,WAAW,CAAChB,MAAnB,EAA2B;AACzB,UAAMO,CAAC,GAAGS,WAAW,CAACQ,GAAZ,EAAV;AACA,QAAIC,CAAC,GAAGlB,CAAC,GAAG,CAAZ;;AAEA,WAAOkB,CAAC,GAAGnC,KAAK,CAACmB,MAAN,CAAaT,MAAjB,IAA2BV,KAAK,CAACmB,MAAN,CAAagB,CAAb,EAAgBL,IAAhB,KAAyB,SAA3D,EAAsE;AACpEK,MAAAA,CAAC;AACF;;AAEDA,IAAAA,CAAC;;AAED,QAAIlB,CAAC,KAAKkB,CAAV,EAAa;AACXrB,MAAAA,KAAK,GAAGd,KAAK,CAACmB,MAAN,CAAagB,CAAb,CAAR;AACAnC,MAAAA,KAAK,CAACmB,MAAN,CAAagB,CAAb,IAAkBnC,KAAK,CAACmB,MAAN,CAAaF,CAAb,CAAlB;AACAjB,MAAAA,KAAK,CAACmB,MAAN,CAAaF,CAAb,IAAkBH,KAAlB;AACD;AACF;AACF,C,CAED;AACA;;;AACA,SAASsB,yBAAT,CAAoCpC,KAApC,EAA2C;AACzC,QAAMqC,WAAW,GAAGrC,KAAK,CAACqC,WAA1B;AACA,QAAMV,GAAG,GAAG3B,KAAK,CAACqC,WAAN,CAAkB3B,MAA9B;AAEAe,EAAAA,WAAW,CAACzB,KAAD,EAAQA,KAAK,CAACkB,UAAd,CAAX;;AAEA,OAAK,IAAIoB,IAAI,GAAG,CAAhB,EAAmBA,IAAI,GAAGX,GAA1B,EAA+BW,IAAI,EAAnC,EAAuC;AACrC,QAAID,WAAW,CAACC,IAAD,CAAX,IAAqBD,WAAW,CAACC,IAAD,CAAX,CAAkBpB,UAA3C,EAAuD;AACrDO,MAAAA,WAAW,CAACzB,KAAD,EAAQqC,WAAW,CAACC,IAAD,CAAX,CAAkBpB,UAA1B,CAAX;AACD;AACF;AACF;;AAED,eAAe;AACbqB,EAAAA,QAAQ,EAAExC,sBADG;AAEb0B,EAAAA,WAAW,EAAEW;AAFA,CAAf","sourcesContent":["// ~~strike through~~\n//\n\n// Insert each marker as a separate text token, and add it to delimiter list\n//\nfunction strikethrough_tokenize (state, silent) {\n  const start = state.pos\n  const marker = state.src.charCodeAt(start)\n\n  if (silent) { return false }\n\n  if (marker !== 0x7E/* ~ */) { return false }\n\n  const scanned = state.scanDelims(state.pos, true)\n  let len = scanned.length\n  const ch = String.fromCharCode(marker)\n\n  if (len < 2) { return false }\n\n  let token\n\n  if (len % 2) {\n    token         = state.push('text', '', 0)\n    token.content = ch\n    len--\n  }\n\n  for (let i = 0; i < len; i += 2) {\n    token         = state.push('text', '', 0)\n    token.content = ch + ch\n\n    state.delimiters.push({\n      marker,\n      length: 0,     // disable \"rule of 3\" length checks meant for emphasis\n      token: state.tokens.length - 1,\n      end: -1,\n      open: scanned.can_open,\n      close: scanned.can_close\n    })\n  }\n\n  state.pos += scanned.length\n\n  return true\n}\n\nfunction postProcess (state, delimiters) {\n  let token\n  const loneMarkers = []\n  const max = delimiters.length\n\n  for (let i = 0; i < max; i++) {\n    const startDelim = delimiters[i]\n\n    if (startDelim.marker !== 0x7E/* ~ */) {\n      continue\n    }\n\n    if (startDelim.end === -1) {\n      continue\n    }\n\n    const endDelim = delimiters[startDelim.end]\n\n    token         = state.tokens[startDelim.token]\n    token.type    = 's_open'\n    token.tag     = 's'\n    token.nesting = 1\n    token.markup  = '~~'\n    token.content = ''\n\n    token         = state.tokens[endDelim.token]\n    token.type    = 's_close'\n    token.tag     = 's'\n    token.nesting = -1\n    token.markup  = '~~'\n    token.content = ''\n\n    if (state.tokens[endDelim.token - 1].type === 'text' &&\n        state.tokens[endDelim.token - 1].content === '~') {\n      loneMarkers.push(endDelim.token - 1)\n    }\n  }\n\n  // If a marker sequence has an odd number of characters, it's splitted\n  // like this: `~~~~~` -> `~` + `~~` + `~~`, leaving one marker at the\n  // start of the sequence.\n  //\n  // So, we have to move all those markers after subsequent s_close tags.\n  //\n  while (loneMarkers.length) {\n    const i = loneMarkers.pop()\n    let j = i + 1\n\n    while (j < state.tokens.length && state.tokens[j].type === 's_close') {\n      j++\n    }\n\n    j--\n\n    if (i !== j) {\n      token = state.tokens[j]\n      state.tokens[j] = state.tokens[i]\n      state.tokens[i] = token\n    }\n  }\n}\n\n// Walk through delimiter list and replace text tokens with tags\n//\nfunction strikethrough_postProcess (state) {\n  const tokens_meta = state.tokens_meta\n  const max = state.tokens_meta.length\n\n  postProcess(state, state.delimiters)\n\n  for (let curr = 0; curr < max; curr++) {\n    if (tokens_meta[curr] && tokens_meta[curr].delimiters) {\n      postProcess(state, tokens_meta[curr].delimiters)\n    }\n  }\n}\n\nexport default {\n  tokenize: strikethrough_tokenize,\n  postProcess: strikethrough_postProcess\n}\n"]},"metadata":{},"sourceType":"module"}